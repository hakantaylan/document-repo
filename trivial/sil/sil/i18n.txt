I have a springboot 4 java 25 based microservice and this microservice has highly dependent on another microservice's data. What is the best practice in this case. Is it a good practice using rest calls to other service and getting related data all the time

Short answer: calling another microservice synchronously for data on every request is usually not best practice‚Äîespecially if your service is highly dependent on that data.

Long answer (the useful one) üëá

The core problem you‚Äôre describing

If Service A cannot function properly without Service B‚Äôs data, then:

You‚Äôve created tight runtime coupling

You inherit B‚Äôs:

latency

downtime

scaling issues

Your system becomes fragile (aka distributed monolith smell)

REST calls themselves are not evil ‚Äî how and when you use them matters.

When REST calls ARE OK

Using REST (or HTTP) between services is fine if all of these are true:

The data is volatile (changes frequently)

You need strong consistency

The call is:

fast

resilient (timeouts, retries, circuit breakers)

The dependency is not on the hot path or can tolerate failure

Example:

‚ÄúCheck user status‚Äù or ‚ÄúValidate permissions‚Äù

When REST calls are a BAD idea (your case, probably)

If your service:

Needs that data for every request

Cannot respond without it

Depends on multiple calls

Reads mostly reference or master data

‚û°Ô∏è That‚Äôs a red flag üö©

Best-practice patterns instead (ranked)
‚úÖ 1. Data duplication (local cache / local copy) ‚Äì MOST COMMON

Each microservice owns its own data, even if it‚Äôs a copy.

How it works

Service B publishes events (Kafka, RabbitMQ, etc.)

Service A listens and stores what it needs locally

Service A never calls B at runtime

Pros

Loose coupling

Faster

More resilient

Scales independently

Cons

Eventual consistency (usually acceptable)

This is the #1 recommended approach in real-world microservice systems.

‚úÖ 2. API Composition (Gateway / Aggregator)

If the dependency is mostly read-only:

A backend-for-frontend (BFF) or gateway calls both services

Core services stay independent

Good for:

UI-facing APIs

Query-heavy use cases

‚ö†Ô∏è 3. Synchronous REST + Resilience (acceptable but risky)

If you must call another service:

You must use:

Timeouts (short!)

Circuit breakers (Resilience4j)

Retries (careful)

Bulkheads

Fallbacks

And:

Never chain multiple services

Never block critical flows

This is damage control, not ideal design.

‚ùå 4. Shared database

Just no üòÑ
This breaks service boundaries completely.

The uncomfortable but important question

If Service A is highly dependent on Service B‚Äôs data‚Ä¶

You should ask:

Are these actually two separate microservices?

Sometimes the correct answer is:

Merge them

Or redefine boundaries (DDD helps a lot here)

Microservices are about independent business capabilities, not just separate deployments.

Practical recommendation for Spring Boot 4 / Java 25

If I were designing this today:

Identify exactly what data is needed

If data is:

Mostly read-only or slow-changing ‚Üí event-driven replication

Frequently changing & critical ‚Üí careful REST with resilience

Use:

Spring Cloud Stream (events)

Resilience4j

Caffeine / Redis for caching

Measure:

Latency

Failure rates

Blast radius

TL;DR

‚ùå Calling another service for required data on every request ‚Üí bad practice

‚úÖ Prefer local data ownership + async sync

‚ö†Ô∏è REST calls are okay only with strong resilience

ü§î If dependency is extreme ‚Üí reconsider service boundaries

If you want, tell me:

What kind of data it is (reference, transactional, user-specific?)

How often it changes

Read vs write ratio

I can suggest a concrete architecture for your exact case.

How can i handle rich query requirements. This microservice depends on other's data and needs searching capabilities including other microservice's data or its nested attributes. How about then?

Great question ‚Äî this is exactly where a lot of ‚Äúclean‚Äù microservice designs get stressed in real life üôÇ
Short version: rich cross-service queries should NOT be solved with runtime REST joins.

Let‚Äôs break this down cleanly and pragmatically.

The fundamental rule (very important)

Microservices are bad at queries that span multiple bounded contexts.

So when you need:

filtering

searching

sorting

pagination

nested attributes

joins across services

‚û°Ô∏è You are no longer doing ‚Äúservice logic‚Äù, you‚Äôre doing ‚Äúquery modeling‚Äù.

That needs a different pattern.

‚ùå What NOT to do

Avoid this at all costs:

Service A
  ‚îî‚îÄ‚îÄ calls Service B
        ‚îî‚îÄ‚îÄ calls Service C
              ‚îî‚îÄ‚îÄ filters in memory


Problems:

N+1 calls

horrible latency

partial failures

impossible pagination

unscalable

‚úÖ The correct patterns (pick based on use case)
ü•á 1. CQRS + Read Model (BEST for rich queries)

This is the gold standard for your scenario.

How it works

Each service owns its write model

Domain events are published when data changes

A query service builds a denormalized read model

Queries hit ONLY the read model

Example
Order Service ‚Üí OrderCreated
User Service  ‚Üí UserUpdated
Product Service ‚Üí ProductPriceChanged
        ‚Üì
   Query Service
        ‚Üì
  Elasticsearch / Postgres / Mongo


Your read model might look like:

{
  "orderId": "123",
  "user": {
    "id": "u1",
    "name": "Alice",
    "tier": "GOLD"
  },
  "products": [
    { "id": "p1", "name": "Laptop", "category": "Electronics" }
  ],
  "totalAmount": 1200
}

Why this works

Rich queries become trivial

No runtime service calls

Scales insanely well

Clean service boundaries remain intact

Trade-off

Eventual consistency (almost always acceptable for search)

ü•à 2. Search Index (Elasticsearch / OpenSearch)

If your requirement is mostly search-heavy:

Pattern

Services emit events

A search index service listens

Builds denormalized documents

All filtering/search happens there

Perfect for:

full-text search

nested attributes

complex filters

aggregations

This is basically CQRS optimized for search.

ü•â 3. API Composition (only for UI-level queries)

Good for:

Admin screens

Dashboards

Low-volume traffic

How it works

BFF calls multiple services

Combines results

Limitations

No deep pagination

Limited filtering

Still synchronous

Use this only if:

traffic is low

queries are simple

latency is acceptable

‚ö†Ô∏è 4. Local materialized views inside your service

If your service needs search:

Subscribe to other service events

Store a local denormalized table

Query it directly

This is like ‚ÄúCQRS-lite‚Äù inside one service.

How to decide (quick decision table)
Requirement	Best choice
Rich filters & nested fields	CQRS read model
Full-text search	Elasticsearch
Strong consistency	REST (limited)
UI aggregation	API Composition
High throughput	Event-driven
Key design mindset shift

Instead of asking:

‚ÄúHow do I query another microservice‚Äôs data?‚Äù

Ask:

‚ÄúWhere should this query live?‚Äù

Answer is almost never:

‚ÄúInside a transactional microservice‚Äù

Spring Boot / Java-specific tips

Events: Kafka / Pulsar / RabbitMQ

Schema: Avro / Protobuf

Query side:

PostgreSQL (JSONB is powerful)

Elasticsearch (nested queries)

Consistency handling:

versioning

idempotent consumers

Hard truth (but helpful)

If you need:

joins

ad-hoc queries

deep filters

nested search

‚û°Ô∏è That service is not a microservice, it‚Äôs a query service. And that‚Äôs OK.

Most successful systems separate:

Write services (microservices)

Read/query services (optimized, denormalized)

TL;DR

‚ùå Don‚Äôt do runtime REST joins

‚úÖ Build a denormalized read model

‚úÖ Use CQRS / Search index

‚ö†Ô∏è Accept eventual consistency

üß† Design queries as first-class citizens

If you want, tell me:

Is this user-facing search?

Required consistency (seconds vs immediate)?

Expected data volume?

I can sketch a concrete architecture tailored to your case.

Does localizing necessary data of other microservice help in this case?

Yes ‚Äî localizing (duplicating) the necessary data from other microservices is not only helpful, it is usually the correct solution for the problem you described.

But it has to be done intentionally, not as an accidental copy-paste of data. Let‚Äôs clarify what ‚Äúgood‚Äù looks like.

What ‚Äúlocalizing data‚Äù really means (the right way)

It means:

Your microservice stores only the subset of data it needs

That data is:

read-optimized

denormalized

The source service remains the system of record

Updates arrive asynchronously (events)

This is not sharing a database and not synchronous REST pulls.

Why localization solves rich queries

Once data is local:

No runtime REST calls

Joins become simple local joins

Nested attributes are trivial

Pagination, sorting, filtering all work properly

Latency drops dramatically

In other words:

You move complexity from runtime to data modeling
and that‚Äôs exactly where it belongs.

What data should be localized?

Use this rule:

Localize data that you READ often and WRITE rarely

Typical examples:

User name, tier, country

Product name, category, price

Organization info

Status flags

Avoid:

Large blobs

Highly volatile fields (unless needed)

How to localize data (best practice)
‚úÖ Event-driven synchronization (preferred)

Source service

UserUpdated ‚Üí { userId, name, tier }


Your service

Subscribes to events

Updates its local store

Uses versioning or timestamps

This gives:

loose coupling

eventual consistency

full autonomy

‚ö†Ô∏è Periodic sync (acceptable fallback)

Scheduled job pulls snapshots

Useful when events aren‚Äôt available

Still better than per-request REST

‚ùå On-demand REST fetch

Only acceptable for:

cache warmup

rare fallback scenarios

Never for:

every request

search queries

What should the localized storage look like?

Depends on query needs:

Query Type	Storage
Simple filters	Relational table
Nested / dynamic	JSONB (Postgres)
Full-text search	Elasticsearch
Aggregations	Column-oriented DB

Often:

One write service ‚Üí many read shapes

Consistency concerns (the big fear)

People worry about:

‚ÄúWhat if the data is stale?‚Äù

Reality:

Search, lists, dashboards tolerate seconds/minutes delay

You can:

display last-updated timestamps

rehydrate on demand if critical

Strong consistency is rarely required for queries

If strong consistency is required:

That data probably belongs in the same service boundary

Signs you‚Äôre doing it right

‚úÖ Your service can run if others are down
‚úÖ No synchronous calls in the hot path
‚úÖ Query logic is simple
‚úÖ Scaling read traffic doesn‚Äôt impact writers

Signs you‚Äôre doing it wrong

‚ùå REST calls inside loops
‚ùå ‚ÄúJust one more field‚Äù creeping in
‚ùå Tight coupling to another service‚Äôs schema
‚ùå Manual fixes when events are missed

A very important mindset shift

Duplication of data is not a problem.
Duplication of responsibility is.

You‚Äôre duplicating data for reading, not business rules ‚Äî that‚Äôs good architecture.

TL;DR

‚úÖ Yes, localizing other service‚Äôs data greatly helps

‚úÖ It is the standard solution for rich queries

‚úÖ Use async events, not REST

‚ö†Ô∏è Accept eventual consistency

üß† If data must be always up-to-date ‚Üí rethink boundaries

If you want, I can help you:

decide which fields to localize

design an event schema

choose storage for your query patterns

Just tell me a bit about your domain.

How about not using localized data but using other service's data as cache. Does this solve my rpoblem

Short answer: No ‚Äî using another service‚Äôs data ‚Äúas a cache‚Äù does not really solve your problem.
It reduces calls, but it keeps the same architectural coupling.

Let‚Äôs unpack why, and when (very narrowly) it can make sense.

What you‚Äôre really proposing

Typically this looks like:

Service A calls Service B

Response is cached (Redis / Caffeine)

Subsequent requests hit the cache instead of B

Sounds nice, but‚Ä¶

Why this does NOT solve rich-query problems
1. You still have runtime dependency

Cold cache = call Service B

Cache eviction = call Service B

Cache inconsistency = call Service B

Your service cannot function independently.

2. Cache ‚â† query model

Caches are:

key-based (getById)

shallow

not designed for:

filtering

sorting

pagination

nested queries

You still can‚Äôt do:

find users where tier = GOLD and country = DE


unless Service B supports it.

3. Pagination breaks

You cannot correctly paginate across:

multiple cached calls

partial datasets

This is one of the biggest practical failures of ‚Äúcache-as-data‚Äù.

4. You inherit the other service‚Äôs API

Your queries are now constrained by:

Service B‚Äôs endpoints

Service B‚Äôs performance

Service B‚Äôs SLA

That‚Äôs tight coupling with lipstick üíÑ

When caching another service‚Äôs data IS acceptable

There are valid use cases ‚Äî just not yours (rich queries).

‚úÖ Good use cases

Lookup by ID

Validation checks

Authorization

Reference checks

Example:

isUserActive(userId)


Here:

cache hit rate is high

no complex queries

stale data risk is small

Cache vs Localized Data (critical distinction)
Aspect	Cache	Localized Data
Ownership	Other service	Your service
Runtime dependency	Yes	No
Query flexibility	Very limited	Full
Pagination	Broken	Correct
Failure tolerance	Low	High
Use for search	‚ùå	‚úÖ
Why cache often becomes a trap

Teams start with:

‚ÄúWe‚Äôll just cache it‚Äù

Then:

more fields added

longer TTLs

manual invalidations

mysterious bugs

stale production data

Eventually it turns into:

‚ÄúWhy is this microservice even separate?‚Äù

The right mental model

Cache is an optimization.
Localized data is a design choice.

A cache cannot replace a proper read model.

If you really must mix both (advanced)

A sane hybrid approach:

Localized read model (primary)

Cache for fallback / warmup

No cache reads on the hot query path

Cache helps performance, not correctness.

TL;DR

‚ùå Using another service‚Äôs data as a cache does not solve rich query needs

‚ùå It keeps tight coupling and breaks pagination/search

‚úÖ Cache is fine for ID-based lookups

‚úÖ Localized data is the correct solution for queries

üß† If you need other service‚Äôs data to query ‚Üí make it local

If you want, I can:

help you spot which data should be localized vs cached

sketch a clean event-driven read model

review your query patterns and recommend storage

Just tell me how your queries look today.

OK. This microservice heavly depend on other microservice's lookup data and we have i18n issue. Dependent microservice does not know anything about massge bundles of other's. How can we solve i18n problem then?

This is a very real problem, and you‚Äôre right to pause here ‚Äî i18n + microservices + localized lookup data is one of those things that looks simple and then explodes later if you get it wrong üòÑ
Good news: there is a clean, battle-tested way to solve it.

First, let‚Äôs name the core issue

You have:

Service A (your service)

Service B (owns lookup/reference data)

Lookup values need to be localized

Service A should not depend on B‚Äôs message bundles

You don‚Äôt want runtime REST calls just for translations

So the question is:

Where does localization live?

The golden rule for i18n in microservices

Text shown to users must be localized at the edge, not deep inside services.

Translation is a presentation concern, not a domain concern.

‚úÖ The recommended solution (clean & scalable)
ü•á Code + Key, not Text

Service B should never send translated text.

Instead, it sends:

{
  "statusCode": "ORDER_STATUS_SHIPPED",
  "i18nKey": "order.status.shipped"
}


Or even just:

{
  "code": "SHIPPED"
}

ü•à Service A owns localization

Service A:

Has its own message bundles

Maps lookup codes ‚Üí i18n keys

Translates based on Accept-Language

Example:

order.status.shipped=Shipped
order.status.shipped.de=Versendet


Service A does:

messageSource.getMessage(i18nKey, null, locale)

Why this works so well

No cross-service i18n dependency

No shared message bundles

No runtime calls

Each service localizes only what it presents

Perfect for localized lookup data

But what if lookup values change?

Good question üëç

Option A ‚Äì Versioned lookup events (best)

Service B emits:

{
  "code": "SHIPPED",
  "semanticMeaning": "ORDER_STATUS_SHIPPED"
}


Service A:

Stores code

Uses its own mapping to i18n keys

Changing display text ‚â† changing domain meaning.

Option B ‚Äì Central Translation Service (use carefully)

Only when:

Many UIs / BFFs

Many languages

Content changes often

But:

This becomes infrastructure, not a domain service

Must be cached aggressively

Usually overkill

‚ùå What NOT to do

Avoid these traps:

‚ùå Service B returns translated strings
‚ùå Shared message bundles across services
‚ùå Service A calls Service B ‚Äújust to translate‚Äù
‚ùå Database-stored translations mixed with business data

These all create tight coupling and release hell.

What about localized lookup tables?

Sometimes people do this:

{
  "code": "SHIPPED",
  "labels": {
    "en": "Shipped",
    "de": "Versendet"
  }
}


This is acceptable only if:

Lookup values are purely UI-facing

Rarely change

Many consumers need them

Even then, prefer:

i18n keys over raw text

Practical Spring Boot advice

In Spring Boot:

Use MessageSource

Keep bundles per service

Support fallback locale

Never expose translated text in internal APIs

Architecture diagram (mental model)
Lookup Service (B)
   ‚îî‚îÄ‚îÄ code = SHIPPED
         ‚Üì
   Your Service (A)
   ‚îî‚îÄ‚îÄ order.status.shipped
         ‚Üì
   User Locale ‚Üí "Versendet"

TL;DR

‚úÖ Do NOT share message bundles

‚úÖ Services exchange codes / semantic keys

‚úÖ Localization happens at the service that presents data

‚ùå Never translate in core domain services

üß† i18n is a UI concern, not a data concern

If you want, tell me:

Is this data shown directly to users or via a BFF?

How many languages?

How often lookup values change?

I can suggest a concrete i18n + event schema that fits your setup perfectly.

Lookups change very rare. Only java and no BFF

Perfect ‚Äî that actually makes the solution much simpler and cleaner üëç
Given:

‚úÖ Lookups change very rarely

‚úÖ Java-only

‚úÖ No BFF

‚úÖ Microservice depends heavily on lookup data

Here is the recommended, low-risk, production-friendly approach.

‚úÖ The cleanest solution for your case
Lookup service owns CODES, not TEXT

Your lookup service should expose (or publish):

{
  "code": "SHIPPED",
  "type": "ORDER_STATUS"
}


That‚Äôs it.
No labels. No languages. No message bundles.

Your service localizes locally

Your service:

Localizes lookup codes

Owns its own message bundles

Does translation using MessageSource

Example:

Lookup code

ORDER_STATUS.SHIPPED


messages_en.properties

ORDER_STATUS.SHIPPED=Shipped


messages_de.properties

ORDER_STATUS.SHIPPED=Versendet

Why this is the best fit for you

Because:

Lookups are stable

No BFF means service = presentation layer

Java-only means MessageSource is perfect

Zero runtime coupling

Zero infra complexity

This is the boring solution ‚Äî and boring is good.

How localized lookup data flows
Lookup Service
   ‚îî‚îÄ‚îÄ ORDER_STATUS + SHIPPED
          ‚Üì (event or sync)
   Your Service
   ‚îî‚îÄ‚îÄ stores code locally
          ‚Üì
   MessageSource + Locale
          ‚Üì
   User-facing text

Handling new lookup values safely

Because lookups change rarely:

Add new code in lookup service

Deploy lookup service

Add message key in your service

Deploy your service

If a key is missing:

fallback to code

log a warning

system keeps working

Spring Boot configuration (simple & solid)
@Bean
MessageSource messageSource() {
    ReloadableResourceBundleMessageSource ms =
        new ReloadableResourceBundleMessageSource();
    ms.setBasename("classpath:messages");
    ms.setDefaultEncoding("UTF-8");
    ms.setFallbackToSystemLocale(false);
    return ms;
}


Usage:

String label = messageSource.getMessage(
    "ORDER_STATUS." + statusCode,
    null,
    locale
);

What about storing translations in DB?

Don‚Äôt.
You gain nothing and add:

schema complexity

caching problems

operational pain

Static bundles are perfect here.

Edge cases & best practices

Always expose code + label in APIs (not just label)

Use enums only inside service, not across services

Never localize inside the lookup service

Document lookup codes clearly

TL;DR

‚úÖ Stable lookup data ‚Üí codes only

‚úÖ Localization lives in the consuming service

‚úÖ Message bundles per service

‚ùå No shared bundles

‚ùå No translation REST calls

This approach scales cleanly and stays maintainable for years.

If you want, I can:

help define a lookup event schema

suggest a fallback strategy

review your API contract for localization safety

Just say the word.

But how can i strictly obey/force this message codes are the same across all microservices. Across all microservices all message codes should be the same, wright? And how to prevent conflict occur (Same message code comes from different microservices)

This is an excellent question ‚Äî you‚Äôve hit the exact point where many teams accidentally re-introduce coupling or chaos.
Short answer: you should NOT try to globally enforce identical message codes across all microservices.
Long answer below üëá (this matters a lot).

The key principle (counter-intuitive but correct)

Message / i18n codes are NOT a shared global contract.
Domain codes are.

Trying to enforce global message codes leads to:

shared libraries

release coupling

‚Äúwho owns this key?‚Äù arguments

hidden dependencies

That‚Äôs exactly what microservices are meant to avoid.

What MUST be globally consistent

These must be consistent across services:

Domain identifiers

Lookup codes

Business semantics

Example (GOOD):

{
  "type": "ORDER_STATUS",
  "code": "SHIPPED"
}


This is the contract.

What must NOT be globally enforced

These must stay service-local:

Message bundle keys

Display text

i18n structure

MessageSource configuration

So how do services map safely without conflict?
‚úÖ Use a deterministic naming convention

Instead of sharing bundles, derive message keys from domain data.

Pattern

<DOMAIN>.<LOOKUP_TYPE>.<CODE>


Example:

order.status.shipped


This key is:

predictable

collision-resistant

derivable at runtime

no registry needed

Every service independently follows the rule.

Why this prevents conflicts

Two different services can both have a SHIPPED code:

ORDER_STATUS.SHIPPED
PAYMENT_STATUS.SHIPPED


But message keys become:

order.status.shipped
payment.status.shipped


No conflict. No coordination. No shared files.

Should we enforce this technically?

You don‚Äôt enforce via runtime, you enforce via process + tooling.

Practical enforcement options
1Ô∏è‚É£ API / event contract defines namespace

Document it clearly:

{
  "lookupType": "ORDER_STATUS",
  "code": "SHIPPED"
}


That implies the i18n key shape.

2Ô∏è‚É£ Static checks (recommended)

Add a build-time check:

Scan message bundles

Ensure keys follow the pattern

Fail the build if not

This is cheap and very effective.

3Ô∏è‚É£ Central documentation (not a service)

One markdown / ADR

One table of lookup types

No shared runtime artifact

What NOT to do (very important)

‚ùå Shared ‚Äúi18n-common‚Äù library
‚ùå Central message bundle repo
‚ùå Translation microservice
‚ùå Runtime validation across services

All of these:

reintroduce coupling

slow deployments

hurt autonomy

But wait ‚Äî what if two services interpret the same code differently?

That‚Äôs a domain problem, not an i18n problem.

If:

ORDER_STATUS.SHIPPED means different things

Then:

your bounded contexts are wrong

Fix domain boundaries, not message keys.

The mental model to keep

Think in layers:

Domain Contract (shared)
   ‚îî‚îÄ‚îÄ ORDER_STATUS + SHIPPED   ‚Üê must match
Presentation (local)
   ‚îî‚îÄ‚îÄ order.status.shipped     ‚Üê private


The mapping is deterministic, not shared.

TL;DR

‚ùå Don‚Äôt globally enforce message bundle keys

‚úÖ Enforce domain lookup codes

‚úÖ Derive i18n keys via convention

‚úÖ Namespace message keys by domain + type

‚ùå No shared i18n libraries

This keeps services:

autonomous

conflict-free

easy to evolve

If you want, I can give you:

a concrete naming convention

a Gradle/Maven build check

a sample ADR you can drop into your repo

Just tell me which one you want.

Maven build check, a sample ADR you can drop into my repo

Perfect! Let‚Äôs handle this step by step. I‚Äôll provide:

A Maven build-time check idea to enforce i18n key conventions.

A sample ADR (Architecture Decision Record) that documents the policy.

This will give you compile-time safety and team alignment.

1Ô∏è‚É£ Maven build-time check for i18n keys

The idea:

At build time, scan all message bundles (messages_*.properties)

Ensure keys follow the naming convention:

<domain>.<lookupType>.<code>   (all lowercase, dot-separated)

Sample Maven plugin setup

We can use the Maven Exec Plugin to run a simple Java class or Groovy script:

pom.xml snippet:

<plugin>
    <groupId>org.codehaus.mojo</groupId>
    <artifactId>exec-maven-plugin</artifactId>
    <version>3.1.0</version>
    <executions>
        <execution>
            <id>check-i18n-keys</id>
            <phase>validate</phase>
            <goals>
                <goal>java</goal>
            </goals>
            <configuration>
                <mainClass>com.example.i18n.I18nKeyValidator</mainClass>
                <classpathScope>compile</classpathScope>
            </configuration>
        </execution>
    </executions>
</plugin>

Sample I18nKeyValidator.java
package com.example.i18n;

import java.io.IOException;
import java.nio.file.*;
import java.util.Properties;
import java.util.regex.Pattern;

public class I18nKeyValidator {

    private static final Pattern KEY_PATTERN = 
        Pattern.compile("^[a-z]+\\.[a-z]+\\.[a-z0-9_]+$");

    public static void main(String[] args) throws IOException {
        Path messagesDir = Paths.get("src/main/resources");
        Files.walk(messagesDir)
            .filter(f -> f.toString().endsWith(".properties"))
            .forEach(I18nKeyValidator::validateFile);
    }

    private static void validateFile(Path path) {
        Properties props = new Properties();
        try {
            props.load(Files.newInputStream(path));
            props.keySet().forEach(k -> {
                String key = k.toString();
                if (!KEY_PATTERN.matcher(key).matches()) {
                    System.err.printf("Invalid i18n key: %s in %s%n", key, path);
                    System.exit(1);
                }
            });
        } catch (IOException e) {
            e.printStackTrace();
            System.exit(1);
        }
    }
}


‚úÖ What this does:

Runs during Maven validate phase

Fails the build if any key violates convention

Encourages deterministic naming

Keeps your microservices autonomous

2Ô∏è‚É£ Sample ADR (Architecture Decision Record)

Create a file:
docs/adr/001-i18n-key-policy.md

# ADR 001: i18n Key Naming Convention

## Context
Our microservices rely on lookup codes from other services. We need to display user-facing text in multiple languages. We want to:

- Avoid cross-service i18n coupling
- Prevent key collisions
- Make keys deterministic and predictable

## Decision
- Lookup codes are **domain-owned** (e.g., `ORDER_STATUS.SHIPPED`)
- Message keys are **local to each service**, derived from domain codes
- **Key convention**: `<domain>.<lookupType>.<code>`  
  - lowercase, dot-separated
  - example: `order.status.shipped`
- No shared message bundle libraries
- No runtime translation service
- Build-time check enforces convention via Maven

## Consequences
- Services remain autonomous
- New lookup codes require only **local bundle additions**
- Avoids conflicts across services
- Eventual consistency is maintained if new codes appear


‚úÖ Benefits of this ADR:

Teams know the rules upfront

Standardizes naming without runtime dependencies

Easy to enforce via Maven check

If you want, I can extend the Maven check to:

Detect duplicate keys across modules

Automatically suggest missing keys for new lookup codes

Warn about missing translations for all supported locales

This would make it full-proof for multiple microservices.

Do you want me to do that next?

yes

Perfect! Let‚Äôs make this full-proof so your Maven build will:

Enforce naming convention

Detect duplicate keys across multiple modules/services

Warn about missing translations for all supported locales

This works well for multi-module Maven projects or multiple microservices in the same repo.

1Ô∏è‚É£ Directory structure assumption

Assume your services have a structure like:

services/
  service-a/
    src/main/resources/messages_en.properties
    src/main/resources/messages_de.properties
  service-b/
    src/main/resources/messages_en.properties
    src/main/resources/messages_de.properties


We want a validator that:

Walks all messages_*.properties files

Validates key naming

Detects duplicates across services

Detects missing translations for all languages

2Ô∏è‚É£ Enhanced I18nKeyValidator.java
package com.example.i18n;

import java.io.IOException;
import java.nio.file.*;
import java.util.*;
import java.util.regex.Pattern;

public class I18nKeyValidator {

    private static final Pattern KEY_PATTERN =
            Pattern.compile("^[a-z]+\\.[a-z]+\\.[a-z0-9_]+$");

    // Define all locales you support
    private static final List<String> SUPPORTED_LOCALES = Arrays.asList("en", "de");

    public static void main(String[] args) throws IOException {
        Path servicesDir = Paths.get("services"); // root dir for all services

        Map<String, String> allKeys = new HashMap<>();
        boolean hasError = false;

        Files.walk(servicesDir)
                .filter(f -> f.toString().endsWith(".properties"))
                .forEach(path -> {
                    String serviceName = path.getParent().getParent().getFileName().toString();
                    try {
                        Properties props = new Properties();
                        props.load(Files.newInputStream(path));
                        props.forEach((k, v) -> {
                            String key = k.toString();
                            // 1. Validate naming
                            if (!KEY_PATTERN.matcher(key).matches()) {
                                System.err.printf("[ERROR] Invalid i18n key: %s in %s%n", key, path);
                                hasError = true;
                            }
                            // 2. Detect duplicates
                            String globalKey = serviceName + ":" + key;
                            if (allKeys.containsKey(key)) {
                                System.err.printf("[ERROR] Duplicate key across services: %s in %s and %s%n",
                                        key, allKeys.get(key), path);
                                hasError = true;
                            } else {
                                allKeys.put(key, path.toString());
                            }
                        });
                    } catch (IOException e) {
                        e.printStackTrace();
                        hasError = true;
                    }
                });

        // 3. Check missing translations
        allKeys.keySet().forEach(key -> {
            for (String locale : SUPPORTED_LOCALES) {
                Path localeFile = Paths.get("services");
                // simplified: assumes messages_<locale>.properties exists alongside en version
                try {
                    Path found = Files.walk(localeFile)
                            .filter(f -> f.getFileName().toString().equals("messages_" + locale + ".properties"))
                            .findFirst().orElse(null);
                    if (found != null) {
                        Properties p = new Properties();
                        p.load(Files.newInputStream(found));
                        if (!p.containsKey(key)) {
                            System.err.printf("[WARN] Missing translation for key '%s' in locale '%s'%n", key, locale);
                        }
                    }
                } catch (IOException e) {
                    e.printStackTrace();
                    hasError = true;
                }
            }
        });

        if (hasError) {
            System.err.println("i18n validation failed!");
            System.exit(1);
        } else {
            System.out.println("i18n validation passed.");
        }
    }
}

‚úÖ Features

Key format validation (<domain>.<lookupType>.<code>)

Duplicate detection across services

Missing translation warning for all locales

3Ô∏è‚É£ Maven setup

Add this in each service‚Äôs pom.xml (or parent pom for multi-module):

<plugin>
    <groupId>org.codehaus.mojo</groupId>
    <artifactId>exec-maven-plugin</artifactId>
    <version>3.1.0</version>
    <executions>
        <execution>
            <id>validate-i18n</id>
            <phase>validate</phase>
            <goals>
                <goal>java</goal>
            </goals>
            <configuration>
                <mainClass>com.example.i18n.I18nKeyValidator</mainClass>
                <classpathScope>compile</classpathScope>
            </configuration>
        </execution>
    </executions>
</plugin>


Now every mvn clean install will validate i18n keys across all services.

4Ô∏è‚É£ ADR update (optional)

Update your ADR to include duplicate detection & missing translations:

### Added Decision
- Build-time validation enforces:
  - Key naming convention
  - Duplicate key detection across services
  - Missing translations for all supported locales
- Maven exec plugin + I18nKeyValidator class runs during `validate` phase


This setup gives you strict enforcement without introducing:

shared message bundles

runtime coupling

translation microservices

Everything stays autonomous, predictable, and safe.

If you want, I can also refactor the validator to automatically generate missing keys stubs for each locale, so developers don‚Äôt have to manually create them ‚Äî that‚Äôs a nice productivity booster.

Do you want me to do that?

Wait this maven plugin checks between message properties in the same microservices but i need to force/check this between microservices. How can i keep domian codes same/consistent between microservices

Ah! Now I understand clearly ‚Äî your concern is domain codes consistency across microservices, not just i18n key formatting inside one service. This is a domain-level problem, not an i18n problem. Let‚Äôs solve it properly.

üîë Core principle

Domain codes (lookup codes, enums, identifiers) are contracts.
They must remain the same across all microservices that depend on them.

i18n keys are local to the service, but domain codes must be consistent.

‚úÖ Options to enforce consistent domain codes across microservices
1Ô∏è‚É£ Shared domain library (code-only)

Create a Java library that contains enums / constants for all shared lookup codes.

All microservices depend on this library as a compile-time dependency.

Library contains only codes, no text.

Example:

// shared-domain-lookup
package com.example.domain;

public enum OrderStatus {
    NEW,
    SHIPPED,
    DELIVERED,
    CANCELLED;
}


Usage in Service A/B:

OrderStatus status = OrderStatus.SHIPPED;


‚úÖ Advantages:

Compile-time safety

No conflicts

Easy to maintain

‚ö†Ô∏è Disadvantage:

You now have a shared artifact ‚Üí versioning required, but this is fine for stable lookups

Perfect for your case because lookups rarely change.

2Ô∏è‚É£ Contract-first with events / registry

If you don‚Äôt want a shared library:

Define a contract repository (YAML/JSON/Avro/Protobuf)

Each service validates its codes against the contract at build-time

Optionally, CI pipeline check ensures no service introduces new codes outside the spec

Example contract (lookup-codes.yaml):

orderStatus:
  - NEW
  - SHIPPED
  - DELIVERED
  - CANCELLED

paymentStatus:
  - PENDING
  - PAID
  - FAILED


Validator reads all services‚Äô code usage and fails build if it diverges

Stored in version control, update via PR ‚Üí traceable

‚úÖ Advantages:

No shared library needed

Explicit contract

Versioned and auditable

‚ö†Ô∏è Slightly more CI/validation work

3Ô∏è‚É£ Domain code ownership by service

Assign one service as owner of each lookup domain

Other services depend on it only via code, never create new codes

CI/CD ensures no service creates conflicting codes

Use event-driven updates for new codes

‚úÖ Works well if you want strict bounded contexts

üîÑ Recommended approach for you

Given your constraints:

Java-only

No BFF

Lookups rarely change

Option 1 (shared domain library) is simplest and most practical:

Service A and Service B depend on the same library for domain codes

i18n message keys in each service are derived from the enum locally

Build-time Maven check can verify:

No i18n key missing for each code

Message keys match convention

You no longer have to worry about collisions because domain codes come from a single source of truth.

Example: Enum + MessageSource mapping
OrderStatus status = OrderStatus.SHIPPED;
String label = messageSource.getMessage(
    "order.status." + status.name().toLowerCase(), null, locale
);


The enum ensures code consistency across microservices

MessageSource ensures localization

No runtime REST calls

No duplication of domain logic

‚ö†Ô∏è Notes on shared domain library

Keep library small and focused

Only codes / enums / constants, no behavior

Version carefully (semantic versioning)

Use CI to prevent multiple versions deployed out-of-sync

TL;DR

‚ùå Don‚Äôt try to enforce domain code consistency via i18n or Maven properties

‚úÖ Use shared domain library (Java enums/constants) for codes

‚úÖ i18n keys stay local to each service

‚úÖ Build-time validation ensures message keys exist for all codes

If you want, I can sketch the complete architecture combining:

shared domain enums

local i18n message bundles per microservice

Maven build-time checks for missing translations

‚Ä¶so you can fully automate consistency and avoid conflicts.

Do you want me to do that next?

Yes please

Perfect! Let‚Äôs design a complete, battle-tested architecture for your setup:

Goals:

Ensure domain codes are consistent across microservices

Keep i18n/localization fully local

Automatically validate at build-time

Avoid runtime coupling

1Ô∏è‚É£ Shared Domain Library (Source of Truth)

Create a small Maven module (or artifact) called shared-domain-lookup:

package com.example.domain;

public enum OrderStatus {
    NEW,
    SHIPPED,
    DELIVERED,
    CANCELLED;
}

public enum PaymentStatus {
    PENDING,
    PAID,
    FAILED;
}


Only contains codes / enums, no text, no behavior

Versioned via Maven (semantic versioning)

All microservices that need these codes depend on this library

‚úÖ Ensures compile-time consistency across microservices

2Ô∏è‚É£ Local i18n per Microservice

Each service defines its own message bundles:

service-a/src/main/resources/messages_en.properties
service-a/src/main/resources/messages_de.properties


Example for OrderStatus:

order.status.new=New
order.status.shipped=Shipped
order.status.delivered=Delivered
order.status.cancelled=Cancelled


Message key derived from enum:

OrderStatus status = OrderStatus.SHIPPED;
String label = messageSource.getMessage(
    "order.status." + status.name().toLowerCase(), null, locale
);


Each microservice can translate independently

No shared bundles, no runtime REST calls

3Ô∏è‚É£ Maven Build-Time Validation

We can extend the previous I18nKeyValidator to:

Scan all enums from shared-domain library

Ensure a message key exists for each enum value in the local message bundles

Warn/fail build if missing

Sample Validator Logic (Conceptual)
for (Enum<?> e : OrderStatus.values()) {
    String key = "order.status." + e.name().toLowerCase();
    if (!messages.containsKey(key)) {
        System.err.println("[ERROR] Missing i18n key: " + key);
        hasError = true;
    }
}


Repeat for all enums in shared-domain library

Can integrate as Exec Maven Plugin in the validate phase

Ensures no enum is left without translation

4Ô∏è‚É£ CI/CD Enforcement

mvn clean install will fail if:

Enum exists but no message key

Message key violates naming convention

Each service can validate independently

Ensures consistency without sharing message bundles

5Ô∏è‚É£ Complete Flow Diagram
Shared Domain Library (single source of truth)
  ‚îî‚îÄ‚îÄ Enum codes: ORDER_STATUS, PAYMENT_STATUS

Service A (Java microservice)
  ‚îú‚îÄ‚îÄ Depends on shared-domain library
  ‚îú‚îÄ‚îÄ Local messages_en.properties / messages_de.properties
  ‚îî‚îÄ‚îÄ Build-time validation: Enum ‚Üí message key exists

Service B (Java microservice)
  ‚îú‚îÄ‚îÄ Same as Service A


At runtime:

Service A/B use enums from library ‚Üí guaranteed consistent codes

Service A/B use local message bundles ‚Üí localized text

No runtime dependency between services

6Ô∏è‚É£ ADR (Architecture Decision Record)

docs/adr/002-domain-enum-i18n.md

# ADR 002: Domain Enums + Local i18n Policy

## Context
Multiple microservices rely on the same lookup codes (ORDER_STATUS, PAYMENT_STATUS).  
We need consistent codes across services and localized user-facing text.

## Decision
- Create a shared domain library with **enums/constants** for all lookup codes
- Each microservice:
  - Depends on shared library
  - Maintains **local message bundles**
  - Derives i18n keys from enum values (lowercase, dot-separated)
- Maven build-time validation ensures:
  - All enums have a corresponding i18n key
  - i18n key naming convention is respected
- No shared message bundles
- No runtime REST calls for translations

## Consequences
- Codes are guaranteed consistent across microservices
- Localization stays fully local
- Builds fail early if translation is missing
- Services remain autonomous


‚úÖ Result

Domain code consistency: Guaranteed by shared enum library

Localization: Local to each service

Automation: Maven validation enforces rules

Scalable: Adding new codes is easy and safe

If you want, I can write a full ready-to-use Maven Exec Plugin + Validator that scans all enums from a shared library and validates message bundles ‚Äî this can be dropped directly into your microservices.

Do you want me to do that?

Yes

Perfect! Let‚Äôs build a ready-to-drop Maven Exec Plugin + Validator that:

Reads all enums from your shared domain library

Scans local message bundles (messages_*.properties)

Checks every enum has a corresponding i18n key

Fails build if any key is missing or violates naming convention

This will fully automate domain code + i18n consistency across microservices.

1Ô∏è‚É£ Project setup

Shared domain library: shared-domain-lookup

Microservice: service-a (depends on shared library)

Message bundles in src/main/resources/

2Ô∏è‚É£ Validator Java Class
package com.example.i18n;

import java.io.IOException;
import java.io.InputStream;
import java.lang.reflect.Modifier;
import java.util.*;
import java.util.regex.Pattern;
import java.util.stream.Collectors;

public class EnumI18nValidator {

    // Define supported locales
    private static final List<String> SUPPORTED_LOCALES = Arrays.asList("en", "de");

    // Enum package(s) to scan
    private static final String ENUM_PACKAGE = "com.example.domain";

    // Key naming convention
    private static final Pattern KEY_PATTERN =
            Pattern.compile("^[a-z]+\\.[a-z]+\\.[a-z0-9_]+$");

    public static void main(String[] args) throws IOException, ClassNotFoundException {
        boolean hasError = false;

        // 1. Load all enums in the package
        List<Class<?>> enumClasses = getEnumsFromPackage(ENUM_PACKAGE);

        for (Class<?> enumClass : enumClasses) {
            String domain = enumClass.getSimpleName().toLowerCase(); // e.g., OrderStatus -> orderstatus
            Object[] constants = enumClass.getEnumConstants();

            // 2. Check message bundles for each locale
            for (String locale : SUPPORTED_LOCALES) {
                Properties props = loadProperties(locale);
                for (Object constant : constants) {
                    String code = constant.toString().toLowerCase();
                    String key = domain + "." + code; // key naming convention
                    if (!KEY_PATTERN.matcher(key).matches()) {
                        System.err.printf("[ERROR] Invalid key format: %s%n", key);
                        hasError = true;
                    }
                    if (!props.containsKey(key)) {
                        System.err.printf("[ERROR] Missing translation for key '%s' in locale '%s'%n",
                                key, locale);
                        hasError = true;
                    }
                }
            }
        }

        if (hasError) {
            System.err.println("i18n validation failed!");
            System.exit(1);
        } else {
            System.out.println("i18n validation passed.");
        }
    }

    // Load properties for a given locale
    private static Properties loadProperties(String locale) throws IOException {
        Properties props = new Properties();
        String fileName = String.format("messages_%s.properties", locale);
        InputStream is = EnumI18nValidator.class.getClassLoader().getResourceAsStream(fileName);
        if (is != null) {
            props.load(is);
        }
        return props;
    }

    // Scan enums in the package
    private static List<Class<?>> getEnumsFromPackage(String packageName) throws ClassNotFoundException, IOException {
        // For simplicity, manually list enums in shared library
        // In production, you can use Reflections library for dynamic scanning
        return Arrays.asList(
                Class.forName("com.example.domain.OrderStatus"),
                Class.forName("com.example.domain.PaymentStatus")
        ).stream().filter(c -> c.isEnum() && !Modifier.isAbstract(c.getModifiers())).collect(Collectors.toList());
    }
}

‚úÖ Features

Scans all enums in shared library

Validates message key naming convention

Checks translations exist for all supported locales

Fails the build if any error is found

Note: For dynamic scanning of all enums, you can integrate the Reflections library. For small projects, manually listing enums is simpler.

3Ô∏è‚É£ Maven Plugin Setup

Add to your microservice pom.xml:

<plugin>
    <groupId>org.codehaus.mojo</groupId>
    <artifactId>exec-maven-plugin</artifactId>
    <version>3.1.0</version>
    <executions>
        <execution>
            <id>validate-enum-i18n</id>
            <phase>validate</phase>
            <goals>
                <goal>java</goal>
            </goals>
            <configuration>
                <mainClass>com.example.i18n.EnumI18nValidator</mainClass>
                <classpathScope>compile</classpathScope>
            </configuration>
        </execution>
    </executions>
</plugin>


Runs in validate phase ‚Üí build fails early if any enum key or translation is missing

Supports multiple locales via SUPPORTED_LOCALES

4Ô∏è‚É£ How it works at runtime
Shared Library
  ‚îî‚îÄ‚îÄ OrderStatus.SHIPPED
Service A
  ‚îú‚îÄ‚îÄ messages_en.properties ‚Üí orderstatus.shipped=Shipped
  ‚îú‚îÄ‚îÄ messages_de.properties ‚Üí orderstatus.shipped=Versendet
  ‚îî‚îÄ‚îÄ Validator ‚Üí checks enum ‚Üî message key mapping


Compile-time safety for domain code consistency

Localized messages are independent per service

No cross-service runtime calls needed

5Ô∏è‚É£ Optional Improvements

Auto-generate missing keys stub for locales

Integrate Reflections library for dynamic enum scanning

CI/CD can run validator for all microservices

This is now a full automated solution that:

Guarantees domain codes consistency across microservices

Ensures message keys exist locally for all enums

Keeps i18n fully local

If you want, I can provide a version that dynamically scans all enums in the shared library without manually listing them, which makes it fully plug-and-play for any future enums.

Do you want me to do that next?

Yes

Perfect! Let‚Äôs make this fully dynamic ‚Äî no manual enum listing, fully plug-and-play. We‚Äôll use the Reflections library to scan the shared domain library at build-time.

1Ô∏è‚É£ Add Reflections dependency

In your microservice pom.xml:

<dependency>
    <groupId>org.reflections</groupId>
    <artifactId>reflections</artifactId>
    <version>0.10.2</version>
</dependency>


This lets us scan all classes in a package dynamically, including enums.

2Ô∏è‚É£ Dynamic Enum + i18n Validator
package com.example.i18n;

import org.reflections.Reflections;
import java.io.IOException;
import java.io.InputStream;
import java.lang.reflect.Modifier;
import java.util.*;
import java.util.regex.Pattern;

public class EnumI18nValidatorDynamic {

    private static final List<String> SUPPORTED_LOCALES = Arrays.asList("en", "de");

    // Package of your shared domain enums
    private static final String ENUM_PACKAGE = "com.example.domain";

    // Key naming convention
    private static final Pattern KEY_PATTERN =
            Pattern.compile("^[a-z]+\\.[a-z]+\\.[a-z0-9_]+$");

    public static void main(String[] args) throws IOException {
        boolean hasError = false;

        // 1Ô∏è‚É£ Dynamically scan all enums in the package
        Reflections reflections = new Reflections(ENUM_PACKAGE);
        Set<Class<? extends Enum>> enumClasses = reflections.getSubTypesOf(Enum.class);

        for (Class<? extends Enum> enumClass : enumClasses) {
            if (Modifier.isAbstract(enumClass.getModifiers())) continue;

            String domain = enumClass.getSimpleName().toLowerCase();
            Enum<?>[] constants = enumClass.getEnumConstants();

            // 2Ô∏è‚É£ Validate all locales
            for (String locale : SUPPORTED_LOCALES) {
                Properties props = loadProperties(locale);

                for (Enum<?> constant : constants) {
                    String code = constant.name().toLowerCase();
                    String key = domain + "." + code;

                    // Naming convention
                    if (!KEY_PATTERN.matcher(key).matches()) {
                        System.err.printf("[ERROR] Invalid key format: %s%n", key);
                        hasError = true;
                    }

                    // Missing translation
                    if (!props.containsKey(key)) {
                        System.err.printf("[ERROR] Missing translation for key '%s' in locale '%s'%n",
                                key, locale);
                        hasError = true;
                    }
                }
            }
        }

        if (hasError) {
            System.err.println("i18n validation failed!");
            System.exit(1);
        } else {
            System.out.println("i18n validation passed.");
        }
    }

    private static Properties loadProperties(String locale) throws IOException {
        Properties props = new Properties();
        String fileName = String.format("messages_%s.properties", locale);
        InputStream is = EnumI18nValidatorDynamic.class.getClassLoader().getResourceAsStream(fileName);
        if (is != null) props.load(is);
        return props;
    }
}

3Ô∏è‚É£ Maven Plugin Setup
<plugin>
    <groupId>org.codehaus.mojo</groupId>
    <artifactId>exec-maven-plugin</artifactId>
    <version>3.1.0</version>
    <executions>
        <execution>
            <id>validate-enum-i18n-dynamic</id>
            <phase>validate</phase>
            <goals>
                <goal>java</goal>
            </goals>
            <configuration>
                <mainClass>com.example.i18n.EnumI18nValidatorDynamic</mainClass>
                <classpathScope>compile</classpathScope>
            </configuration>
        </execution>
    </executions>
</plugin>


Runs in validate phase

Automatically scans all enums in com.example.domain

Fails build if:

Enum ‚Üí missing translation key

Message key violates naming convention

4Ô∏è‚É£ How it works
Shared Library
  ‚îî‚îÄ‚îÄ OrderStatus, PaymentStatus, etc.

Service A/B
  ‚îú‚îÄ‚îÄ Depends on shared library
  ‚îú‚îÄ‚îÄ messages_en.properties, messages_de.properties
  ‚îî‚îÄ‚îÄ Validator scans enums dynamically ‚Üí checks i18n keys


‚úÖ No manual updates when adding new enums

‚úÖ Build fails early if translation is missing

‚úÖ Keeps domain codes consistent across microservices

‚úÖ Localization stays fully local

5Ô∏è‚É£ Optional Enhancements

Generate stubs for missing keys automatically

Add duplicate key detection if multiple enums map to the same message key

Integrate with CI/CD to scan all microservices

This setup is production-ready, fully dynamic, and ensures:

Domain enums remain consistent across services

All enums have localized messages

Build fails early for missing translations or invalid keys

If you want, I can extend this further to scan multiple microservices in one repo so your CI can enforce global domain code + i18n consistency across all services.

Do you want me to do that?

Yes

Perfect! Now let‚Äôs extend this solution so your CI/build can enforce domain code + i18n consistency across multiple microservices in the same repo. This is ideal for your setup where you have multiple Spring Boot microservices depending on shared lookup codes.

1Ô∏è‚É£ Directory Structure Assumption
services/
  service-a/
    src/main/resources/messages_en.properties
    src/main/resources/messages_de.properties
  service-b/
    src/main/resources/messages_en.properties
    src/main/resources/messages_de.properties
shared-domain-lookup/
  src/main/java/com/example/domain/OrderStatus.java
  src/main/java/com/example/domain/PaymentStatus.java


Shared library contains all enums

Each microservice has its own message bundles

2Ô∏è‚É£ Multi-Service Enum + i18n Validator
package com.example.i18n;

import org.reflections.Reflections;

import java.io.IOException;
import java.io.InputStream;
import java.lang.reflect.Modifier;
import java.nio.file.*;
import java.util.*;
import java.util.regex.Pattern;

public class MultiServiceEnumI18nValidator {

    // Supported locales
    private static final List<String> SUPPORTED_LOCALES = Arrays.asList("en", "de");

    // Package for shared enums
    private static final String ENUM_PACKAGE = "com.example.domain";

    // Key format
    private static final Pattern KEY_PATTERN =
            Pattern.compile("^[a-z]+\\.[a-z]+\\.[a-z0-9_]+$");

    // Root directory containing all microservices
    private static final String SERVICES_ROOT = "services";

    public static void main(String[] args) throws IOException {
        boolean hasError = false;

        // 1Ô∏è‚É£ Dynamically scan shared enums
        Reflections reflections = new Reflections(ENUM_PACKAGE);
        Set<Class<? extends Enum>> enumClasses = reflections.getSubTypesOf(Enum.class);

        for (Class<? extends Enum> enumClass : enumClasses) {
            if (Modifier.isAbstract(enumClass.getModifiers())) continue;

            String domain = enumClass.getSimpleName().toLowerCase();
            Enum<?>[] constants = enumClass.getEnumConstants();

            // 2Ô∏è‚É£ Validate each microservice
            Files.list(Paths.get(SERVICES_ROOT))
                    .filter(Files::isDirectory)
                    .forEach(serviceDir -> {
                        try {
                            for (String locale : SUPPORTED_LOCALES) {
                                Properties props = loadProperties(serviceDir, locale);

                                for (Enum<?> constant : constants) {
                                    String code = constant.name().toLowerCase();
                                    String key = domain + "." + code;

                                    // Naming convention
                                    if (!KEY_PATTERN.matcher(key).matches()) {
                                        System.err.printf("[ERROR] Invalid key format: %s in %s%n", key, serviceDir);
                                        hasError = true;
                                    }

                                    // Missing translation
                                    if (!props.containsKey(key)) {
                                        System.err.printf("[ERROR] Missing translation for key '%s' in service '%s', locale '%s'%n",
                                                key, serviceDir.getFileName(), locale);
                                        hasError = true;
                                    }
                                }
                            }
                        } catch (IOException e) {
                            e.printStackTrace();
                            hasError = true;
                        }
                    });
        }

        if (hasError) {
            System.err.println("Multi-service i18n validation failed!");
            System.exit(1);
        } else {
            System.out.println("Multi-service i18n validation passed.");
        }
    }

    private static Properties loadProperties(Path serviceDir, String locale) throws IOException {
        Properties props = new Properties();
        Path propFile = serviceDir.resolve("src/main/resources/messages_" + locale + ".properties");
        if (Files.exists(propFile)) {
            try (InputStream is = Files.newInputStream(propFile)) {
                props.load(is);
            }
        }
        return props;
    }
}

3Ô∏è‚É£ How it works

Scans all enums in the shared library

Iterates over all microservices in the repo

Checks for each locale:

Message key exists for each enum value

Key follows naming convention

‚úÖ Build fails if:

Missing translation in any service

Invalid message key format

4Ô∏è‚É£ Maven Integration (in CI)

You can add this in a parent POM or run it via CI directly:

<plugin>
    <groupId>org.codehaus.mojo</groupId>
    <artifactId>exec-maven-plugin</artifactId>
    <version>3.1.0</version>
    <executions>
        <execution>
            <id>validate-multi-service-enum-i18n</id>
            <phase>validate</phase>
            <goals>
                <goal>java</goal>
            </goals>
            <configuration>
                <mainClass>com.example.i18n.MultiServiceEnumI18nValidator</mainClass>
                <classpathScope>compile</classpathScope>
            </configuration>
        </execution>
    </executions>
</plugin>


Runs before compile ‚Üí fails early

Works for all microservices in the repo

5Ô∏è‚É£ Benefits

Domain codes consistency guaranteed (all services use same enums)

i18n/localization consistency: no service misses a translation

Autonomous microservices: message bundles are local

Scalable: supports adding new services or enums dynamically

6Ô∏è‚É£ Optional Enhancements

Detect duplicate keys across services

Auto-generate missing translation stubs for developers

CI can run this for pull requests ‚Üí prevents inconsistencies before merge

With this setup, you have full-proof enforcement of:

Shared domain codes

Localized messages

Multi-microservice consistency

If you want, I can extend this validator to automatically generate missing message bundle entries for all locales and all services ‚Äî so developers don‚Äôt have to manually create them